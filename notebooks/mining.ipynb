{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set huggingface cache folder, must be done before loading the module\n",
    "# adjust to your liking\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"~/disk1/huggingface_cache/\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"~/disk1/huggingface_cache/\"\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "__SRC = os.path.abspath(\".\") + \"/..\"\n",
    "__DATA = __SRC + \"data\"\n",
    "__NOTEBOOKS = __SRC + \"notebooks\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mining beliefs\n",
    "\n",
    "An example on `roberta-base`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy\n",
    "\n",
    "from miners.baert import BaertMiner\n",
    "from miners.mine import LAMA_BAERT_MINER as mining_config\n",
    "\n",
    "# load mining dataset\n",
    "lama_dataset = load_dataset(\"lama\")\n",
    "dataset_size = len(lama_dataset)\n",
    "\n",
    "# mining\n",
    "nr_random_entries = 1000\n",
    "random_entries_indexes = numpy.random.randint(low=0, high=dataset_size,\n",
    "                                              size=nr_random_entries)\n",
    "K = 100\n",
    "mining_config.update({\"K\":K,\n",
    "                      \"indexes\": random_entries_indexes})\n",
    "miner = BaertMiner(\"roberta-base\", \"roberta\", device=\"cuda\")\n",
    "predictions = miner.mine(lama_dataset[\"train\"], mining_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Belief precision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from miners.validation.precision import precisions_at\n",
    "\n",
    "ground_truths, model_predictions = list()\n",
    "for instance in predictions:\n",
    "    ground_truths.append(instance[\"ground_truth_prediction\"])\n",
    "    model_predictions.append(instance[\"prediction\"])\n",
    "\n",
    "precisions = precisions_at(model_predictions, ground_truths, K=K)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Belief precision by predicate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract predicates\n",
    "predicates = numpy.array([lama_dataset[\"train\"][i][\"predicate_id\"] for i in random_entries_indexes])\n",
    "unique_predicates = numpy.unique(predicates)\n",
    "predicate_indexes = [(predicate, numpy.argwhere(predicates == predicate).squeeze())\n",
    "                     for predicate in unique_predicates]\n",
    "\n",
    "precisions_on_predicate = dict()\n",
    "for predicate, indexes in predicate_indexes:\n",
    "    precisions_on_predicate[predicate] = precisions_at([model_predictions[i] for i in indexes],\n",
    "                                                       [ground_truths[i] for i in indexes],\n",
    "                                                       K=K)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Precisions\n",
    "Precision curves on the whole dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "# https://coolors.co/palette/ffbe0b-fb5607-ff006e-8338ec-3a86ff\n",
    "output_notebook()\n",
    "\n",
    "precision_plot = figure(title=f\"Precision@{K}\", x_axis_label=\"K\", y_axis_label=\"Precision\")\n",
    "precision_plot.line(precisions[0].astype(int), precisions[1], legend_label=\"precision\",\n",
    "                    line_width=3, line_color=\"#FFBE0B\")\n",
    "precision_plot.legend.location=\"bottom_right\"\n",
    "show(precision_plot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Precision on specific relations\n",
    "Precision curves aggregated by relation type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for predicate, indexes in predicate_indexes:\n",
    "    precision_plot = figure(title=f\"Precision@K on predicate: {predicate}\", x_axis_label=\"K\", y_axis_label=\"Precision\")\n",
    "    precision_plot.line(precisions_on_predicate[predicate][0].astype(int),\n",
    "                        precisions_on_predicate[predicate][1], legend_label=f\"{predicate}\",\n",
    "                        line_width=3, line_color=\"#FFBE0B\")\n",
    "\n",
    "precision_plot.legend.location=\"bottom_right\"\n",
    "show(precision_plot)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
